# 텍스트 처리 지식 없이 잠정 3위까지 올라가기 그리고 최종 탈락

## :whale: 순서
* [팀 소개](#whale-팀-소개)
* [참가 계기](#whale-참가-계기)
* [진행 과정 및 문제 접근 방식](#whale-진행-과정-및-문제-접근-방식)
  * 전체적인 진행 과정
  * 베이스라인 모델 요약
  * 텍스트 데이터 처리
  * 네트워크 구조
  * 라벨이 없는(라벨이 -1인) 데이터 처리
  * 앙상블 처리
* [스코어 개선 과정 요약](#whale-스코어-개선-과정-요약)
* [후기](#whale-후기)

## :whale: 팀 소개
안녕하세요! 카카오 쇼핑 카테고리 분류 대회에 참가한 S2Bstar 팀입니다. 이번 대회에서 TEST 스코어로 3위(잠정 3위)를 했었지만, 입상 조건을 충족하지 못하여 최종 탈락하게되었습니다. 최종 결과가 조금 아쉬웠지만 팀원들과 정말 즐겁게 대회에 참여하고 많은 것을 배웠습니다. 저희는 자연어 처리에 대한 지식이 모두 전무한 상태로 시작했지만, 반복적인 데이터 분석을 바탕으로 점수를 지속적으로 높여갔습니다. 이 글에서는 저희 팀의 수행과정, 시도했던 아이디어들 그리고 최종 탈락 이유에 대해서 다루어보려고 합니다.

저희 팀은 총 세 명으로 구성되어 있습니다. 한 명은 작은 스타트업에서 데이터 분석 일을 맡고 있고, 다른 한 명은 대기과학 박사 과정 중에 있고, 나머지 한 명은 물리학과 학부생 2학년이고 곧 군대에 들어간다고 합니다. 서로 다른 계기에 의해 데이터 분석 분야에 관심을 갖게 되었고, 2018년 초에 팀을 형성해서 지속적으로 캐글 대회를 중심으로 참여하고 데이터 분석을 해왔습니다. 


## :whale: 참가 계기
저희 팀은 데이터 분석 대회에 참여하여 재미있게 즐기며 실력을 기르는 것이 목표입니다. 마침 카카오 아레나에서 쇼핑 카테고리 분류 대회를 개최한다고 하여 관심을 가지고 참여하게 되었습니다. 특히, 저희는 텍스트 데이터에 대한 처리 경험이 전무하였기에, 이번 기회를 통해 텍스트 데이터 처리에 대해 많이 배우고 생각해보고자 참여하게 되었습니다.


## :whale: 진행 과정 및 문제 접근 방식

### :octopus: 전체적인 진행 과정
![](/img/fig1.png)

### :octopus: 베이스라인 모델 요약
저희 팀은 카카오에서 제공한 베이스라인 모델을 바탕으로 모델을 만들어나갔습니다. 저희 모델에 대한 내용에 앞서 간단하게 베이스라인 모델에 대해 얘기해보고자 합니다. 

베이스라인 모델의 구성은 다음과 같습니다. 텍스트 데이터 처리를 위해 정규표현식을 이용하여 특수문자를 공백으로 치환하고, 공백을 기준으로 문장을 토큰화 합니다. 하나의 토큰(단어)은 해시함수를 통해 유한한 길이의 양의 정수에 대응되고, 이는 다시 고정된 길이의 학습가능한 벡터로 대응(keras.layers.embedding)됩니다. 한 문장에 존재하는 모든 단어 벡터를 합하여(중복된 단어 허용) 해당 문장에 대응되는 고정된 길이의 벡터를 생성합니다. 이렇게 생성된 문장 벡터는 분류기 모델의 입력으로 사용됩니다. 

베이스라인 모델의 분류기는 fully-connected layer 들로 구성된 뉴럴 네트워크이며, 출력 레이너는 가능한 '대/중/소/세'  조합의 수인 4215개의 뉴런을 가집니다. 이를 통해 해당 모델은 Multi-class classification 을 수행합니다.  


### :octopus: 텍스트 데이터 처리
저희 팀원들은 모두 텍스트 데이터에대한 처리가 처음이다보니, 많은 노력과 시간을 이 과정에 가장 많이 쏟아부었고, 가장 효율이 나지 않은 기간이기도 했습니다. 시도했던 여러  중에서 높은 개선을 보인 두가지 처리 과정에 대해 말해보려고 합니다.

#### 형태소 분석기 적용
베이스라인 모델의 토큰화 성능을 높이기 위해 가장 먼저 한 것은 잘 알려진 한국어 형태소 분석기를 적용하는 것 이었습니다. 사용한 형태소 분석기는 khaiii, kkma, okt 등의 라이브러리를 사용하였습니다. 한 문장에 세 형태소 분석기를 통해 명사에 해당하는 단어만 가지고 토큰화를 진행하였고, 해당 토큰들은 모두 하나의 리스트로 합쳐졌습니다. 각 토크나이저 마다 강점이 다르기에 세 토크나이저 모두를 사용하였고, 하나의 토크나이저를 사용한 것보다 개선된 점수를 보여주었습니다. 이때 사용된 입력 문장은 product, brand, maker, maker 의 텍스트가 하나의 텍스트로 이어붙여서 구성되었습니다.

#### 카테고리 명 저장(소/세 카테고리 단어 저장)
형태소 분석기 적용 후 성능이 개선되기는 했지만, 대/중 카테고리에 비해 소/세 카테고리의 정확도는 상대적으로 낮았습니다. 소/세 카테고리를 정확히 맞추지 못한 데이터의 카테고리를 살펴보았더니 '3.1채널',  '5.1채널', '1단계 분유', 등등과 같은 경우를 잘 맞추지 못했습니다. '3.1', '5.1' 같은 숫자들은 소/세 카테고리를 구분할 때 중요한 기준이 되는데, 입력 문장을 살펴보면 tokenizing 과정에서 이러한 숫자 들이 제거되었음을 알게 되었습니다. 

어떻게 하면 이 문제를 일반화하여 처리할 수 있을까 고민하다 보니 카테고리 명을 활용하면 되겠다는 생각이 들었습니다. cate1.json에는 카테고리 명들이 나열되어 있기 때문에 모두 핵심단어들이라고 생각했습니다. 그래서 저희 팀은 cate1.json 에 있는 단어 또는 숫자조합이라면 무조건 코퍼스에 포함시키는 전처리 과정을 적용했습니다.

모든 카테고리 명을 띄어쓰기와 '/' 를 기준으로 토큰화 한것과 Kkma 를 이용해 토큰화를 모두 합쳐서 토큰화된 카테고리명을 저장하였습니다. 그리고, 텍스트 데이터 처리 전에 주어진 문장에서 토큰화된 카테고리명과 동일한 토큰을 따로 기록하였다가, 네트워크의 입력에 추가하였습니다.

일반적인 방법을 통해 이러한 과정이 수행될 수 있다면 더 좋을 것 같습니다.

### :octopus: 네트워크 구조
다양한 구조를 실험해보았지만, 최종적으로 사용된 네트워크 구조는 베이스라인 모델과 거의 동일합니다. 임베딩 레이어및 그 외의 레이어의 뉴런의 수를 조정하고, sigmoid 뉴런을 relu 로 치환하고, Soft-max layer 를 추가하였습니다. 또한 입력으로 img_feat 을 추가하였습니다.

#### 임베딩 및 추론 네트워크
저희는 대회 진행 중 효율적인 실험을 위해 네트워크를 임베딩 레이어와 그외의 추론 과정을 분리하여 네트워크(이하 추론 네트워크)를 구성하였습니다. 임베딩 네트워크에는 오직 텍스트 데이터만 입력으로 사용되며 4215개의 카테고리 분류를 수행합니다. 해당 과정을 통해 학습된 네트워크의 중간 레이어를 추론 네트워크의 입력으로 사용하였습니다. 추론 네트워크에서는 임베딩 네트워크를 통해 임베딩된 벡터와 img_feat 을 입력으로 하여, 4215 개의 카테고리 분류를 수행합니다.

#### 모델 사이즈가 최종 탈락 원인
최종 제출 모델의 임베딩 네트워크 크기는 5 GB 정도이며, 추론 네트워크는 900 MB 정도입니다.임베딩 과 추론 네트워크를 나눈 후, 임베딩 네트워크의 존재를 잊고 있었습니다. 추론 모델의 크기만 생각하다 조건을 충족한 것으로 착각하여 최종 제출 모델의 사이즈가 1 GB 를 넘었습니다. 임베딩 네트워크에서 학습 이후 사용되지 않는 부분을 제거하고, 추론 네트워크를 포함하여 하이퍼 파라미터의 크기를 낮추면 충분히 1 GB 이하로 모델을 제출할 것으로 예상 되었지만, 시간 및 컴퓨팅 리소스가 부족하여 추가 수정 기간에 이를 완료하지 못하였습니다.


### :octopus: 라벨이 없는(라벨이 -1인) 데이터 처리
텍스트 데이터 처리 와 네트워크 구조를 수정하며 1월이 다가왔습니다. 대회가 한달 남은 시점에서 어떻게하면 점수를 올릴 수 있을까 궁리하던 차에 홈페이지에 올라온 다음 글이 눈에 띄었습니다. 

> 모든 샘플은 대/중분류 값이 존재하지만 소나 세분류 값은 없을 수도 있습니다. 예측 결과 파일을 제출할 때는 이점을 무시하고 모든 분류에 대해 예측해야합니다. 하지만 채점시에 실제로 존재하지 않는 분류 체계에 대해서는 점수에 영향을 주지 않습니다. 예를 들어 대/중/소까지 분류 값이 존재하는 샘플에 대해서는 세 분류에 대해 어떤 값을 예측하더라도 점수에는 영향을 주지 않습니다.

그리고 네트워크의 정확도를 낮추는 주요 원인 중 하나는 s/d 카테고리가 -1(존재하지 않는 카테고리)로 예측되는 경우가 많았습니다. -1 인 라벨은 s/d 카테고리에만 존재합니다. 따라서 우리는 다음 표에서와 같이 점수를 깍아내리는 부분인 네트워크가 s/d 를 -1로 예측한 라벨을 존재하는 다른 라벨로 치환하고자 하였습니다. 이 과정에서 저희 팀은 서로 다른 두가지 관점에서 이를 진행하였습니다. 네트워크 모델에 의존성이 있는 처리와 없는 것 두가지 입니다. 

|       | -1 로 예측한 경우  | -1 외의 값으로 예측한 경우 |
| ----- | -------------- | --------------------- |
| 라벨이 -1 인 경우  | 점수 영향 X  | 점수 영향 X |
| 라벨이 -1 이 아닌 경우  |  점수 영향 O  | - |

#### 의존성 있는 처리
네트워크 모델의 출력 중 b/m/s/d 에 대한 예측 값을 b’/m’/s’/d’ 이라고 한다면, 우리가 원하는 것은 다음 수식과 같습니다. s’/d’ 의 값이 -1 이고, 주어진 b’/m’에 대해 가장 높은 빈도수로 존재하는 -1 이 아닌 라벨 s/d 를 새로운 s’/ d’ 으로 대체하는 것 입니다. 이러한 확률 분포를 만들기 위해 학습 데이터를 바탕으로 확률을 계산합니다.

![](/img/fig3.png)

이 과정은 네트워크 모델에의한 예측 결과에 대한 분포가 고려된 처리지만, 예측 모델이 바뀔 때마다 새롭게 다시 계산해야한다는 단점이 있습니다. 학습 데이터의 양이 굉장히 많기 때문에, 모델이 변경될 때 이를 반영하기위해 많은 시간이 걸립니다.

#### 의존성 없는 처리
네트워크 모델에의한 예측 값인 b’/m’ 이 원래의 b/m 을 잘 대변한다고 가정하면, b’/m’ 을 b/m 으로 생각한다면, 다음의 수식을 통해서 s’/d’ 이 -1 일 때, 새로운 s’/d’ 인 s*/d* 을 정의할 수 있습니다. 

![](/img/fig4.png)

이 경우 네트워크 모델에의한 예측 결과에 대한 분포가 고려 되지 않지 않으며, b’/m’ 이 틀리게되면 새로운 s’/d’ 도 틀리게될 가능성이 높습니다. 하지만 네트워크 모델이 달라져도 추가적인 처리 없이 그대로 사용할 수 있고, 네트워크 모델의 b/m 에대한 예측 정확도가 높아진다면, 결과도 쉽게 좋아지게됩니다.


#### 네트워크 모델 상위 n 개 라벨 고려
예측 모델의 top_1 에 대한 prediction confidence 가 낮은 경우들이 주로 틀리는 경우가 많았습니다. 따라서, 상위 n 개를 종합적으로 고려하여 예측 모델을 만들어보고자 시도하였습니다. 다음 수식과 같음. p^n 은 네트워크의 n 번째로 높은 confidence 값이며, 이 때 b 와 m 카테고리에 대한 값을 라벨에 해당하는 인덱스가 1이되도록 하는 one-hot vector 로 나타낸 열 벡터가 b^n, m^n 입니다. 실제 구현 할 때는 n 은 바뀔 수 있습니다.  

![](/img/fig5.png)


#### 상위1위 랭크의 정보가 비어있을 때는 하위 랭크에서 가져오는 치환방식 적용
후처리 후에도 상당히 많은 정보가 비어 있었습니다(-1). 그런데 -1로 두기보다는 어떻게든 논리적으로 추측하여 정보를 채우는 것이 유리하기에 저희는 특별한 방법을 고안해냈습니다. 만약 모델의 output(Confidence rank 1)의 정보가 비어있다면 나머지 하위 랭크에서 정보를 가져와서 채우는 방식입니다. 수식도로 표현하자면 아래와 같습니다.

![](/img/fig7.png)

순차적으로 2, 3, 4, 5 위에서 카테고리 정보를 가져오며, 만약 위의 예시에서 나타난 것처럼 세부 카테고리가 모두 비어있다면 세부 카테고리는 그대로 비워둔 채로 남겨뒀습니다. Dev set에 대하여 적용해본 결과, 17% 비어있던 s 카테고리가 거의 전부 채워졌고, 전부 채워져 있는 경우가 12.4%에서 33.0%로 약 20%포인트가 증가했습니다. 점수의 경우에도 1.050263  1.052212으로 크게 올랐습니다.


#### 앙상블 처리
s/d 카테고리가 -1 로 예측되는 경우 위의 두가지(의존성 있는, 의존성 없는) 처리를 법을 모두 적용하였고, 높은 유사한 성능 개선 효과를 얻었다. 서로 다른 팀원이 독립적으로 진행했었습니다. 우리는 두 모델을 적절히 섞어서 더 나은 모델을 만들고자 하였습니다. 위의 설명된 원리는 같지만, 실제 구현 상의 문제로 의존성 없는 처리는 적용 후에도 s’/d’ 이 -1 인경우가 왕왕 존재했습니다. 하지만 정확도는 의존성 있는 처리 적용 후보다 높았습니다. 따라서, 의존서 없는 처리 후에도 -1 로 나오는 s’/d’ 에 대해서는 의존성 있는 모델의 결과로 대치시켰습니다.

## :whale: 스코어 개선 과정 요약
![](/img/fig6.png)
위 그림은 각 모델을 적용했을 때, 나타난 퍼블릭 스코어를 내략적으로 나타냅니다. 

## :whale: 후기
텍스트 데이터 처리를 처음 다루어봐서, 많은 리서치를 통해 다양한 적용을 수행했습니다. 후처리에 투자한 시간보다도 토큰화 및 임베딩에 많은 시간을 들였지만, 최종적으로 점수를 높이지 못해서 반영되지는 않았습니다. 다른 상위 팀들 모델을 보면서, 처음 보는 방식도 있었고, 생각만 하고 적용하지 못했던 것도 발견할 수 있었습니다. 유사 대회가 있다면, 다음에는 적합한 모델 적용 및 개선에 더 집중할 수 있을 것 같습니다.
팀원들 모두의 백그라운드가 달랐습니다. 모두가 데이터 분석을 하는 것도 아니고, 파이썬, 딥러닝을 하는 것도 아니었습니다. 하지만, 데이터에 대한 분석 및 분석을 바탕으로 모델을 개선하는 것은 우리 팀 모두 공통적으로 할 수 있는 일이었습니다. 더 개선해야겠지만, 분석력은 저희 팀의 동력이자 핵심이며, 앞으로 더 잘해보려고 합니다.


